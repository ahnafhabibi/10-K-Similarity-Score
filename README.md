# 10-K-Risk-Factors-Similarity-Score
This project attempts to generate a signal based on the similarity score of the risk factors section of 10-k documents. 

## Introduction

According to Cohen, Lauren and Malloy, Christopher J. and Nguyen, Quoc, Lazy Prices (March 7, 2019), low similarity scores in Risk Factors section of the 10-k document is a good indicator of a firm's future stock performance. In our project, we develop an innovative algorithm to generate similarity score between consecutive year's 10-k documents in particular the Risk Factors section. Based on these similarity scores, we will group categories of stocks which we will long and shorts. The hypothessis is that shorting low similarity scores stocks will generate profits for us.

## Key Challenges
 There are 2 key challenges to this project. 
 
 #### Challenge 1
 The median word length of 10-K documents is increasing every year. To generate context based similarity score between two documents, it is essential to think about the     computational capability of the machine. In particular, the max context length of Bert is 512 tokens which is extremely small for 10-k documents since each individual section of   the 10-K report can be around 10000 words in length. So, we need to think of alternative ways to generate the similarity score of large documents.

 #### Challenge 2
  It is difficult to prove if the similarity scores generated by the algorithm is superior to traditional methods that only uses Cosine Similairity. Our rationality lies on the fact that pretrained bert based models gives superior context and better embeddings. One of the ways we could prove the superiority is if the groupings of the stock based on our algorithm has better returns compared to traditional method generated by cosine similarity. 
 

## Details of the Algorithm

The Algorithm is inspired from the BertScore Research paper (Zhang, Kishore, Wu, Weinberger, & Artzi, 2020) [3]. However, there are major differences in particular we are implementing this for sentences rather than words as done in the BertScore research paper. We highlight our algorithm below:
Given two large documents,
1) We create two lists of sentences for each documents i.e sentence_lst_1 and sentence_lst_2.
2) From these two lists, we calculate their cosine similarity tensor embeddings from Sbert models [4].
3) Finally, we take the mean of the max of each row and the mean of the max of each column.
4) Our similarity score is the harmonic mean which we call it the f1-score similar to the BertScore paper [3].

![Similarity Matrix](https://github.com/ahnafhabibi/10-K-Similarity-Score/blob/main/similarity_score_example.png)

From the Similarity Matrix above, we consider the mean of the max of each row and column. Then take a weighted average of them in particular the harmonic mean.

## Data Analysis


## Grouping of Stocks based on forward Returns


## Dashboard of the real time performance







## References
[1] Cohen, Lauren and Malloy, Christopher J. and Nguyen, Quoc, Lazy Prices (March 7, 2019). 2019 Academic Research Colloquium for Financial Planning and Related Disciplines, Available at SSRN: https://ssrn.com/abstract=1658471 or http://dx.doi.org/10.2139/ssrn.1658471

[2] Lohding, J. (n.d.). jlohding/sp500-edgar-10k. Hugging Face. Retrieved [July 1, 2024], from https://huggingface.co/jlohding/sp500-edgar-10k

[3] Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., & Artzi, Y. (2020). BERTScore: Evaluating Text Generation with BERT. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 93-104.

[4] Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. Retrieved from https://arxiv.org/abs/1908.10084

